{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf7a16e3",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Reliance Stock Market Prediction\n",
    "\n",
    "**Notebook pattern:** Follows the step-by-step structure of `diabetes_prediction.ipynb` (imports, data load, EDA, preprocessing, training, evaluation, saving `.pkl`, loading and sample prediction).\n",
    "\n",
    "**What this notebook does:**\n",
    "- Takes **user input** for stock symbol, start date, and end date.\n",
    "- Downloads historical data from Yahoo Finance (using `yfinance`).\n",
    "- Performs EDA and feature engineering (moving averages, returns).\n",
    "- Trains a regression model to predict the **next day's Close** price.\n",
    "- Saves the trained model and scaler as `.pkl` files and demonstrates loading them.\n",
    "\n",
    "**Notes:**\n",
    "- Run this notebook in an environment with internet access (e.g., local Jupyter, Colab) for `yfinance` to fetch data.\n",
    "- If running in Google Colab, the download cell will trigger browser downloads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ef34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# optional: yfinance for fetching stock data\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception as e:\n",
    "    print('yfinance not available. Install with `pip install yfinance` if you want to fetch data from Yahoo Finance.')\n",
    "\n",
    "# display settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce16c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) User inputs: stock symbol and date range\n",
    "print('Enter the stock symbol and date range (YYYY-MM-DD). Example for Reliance on NSE: RELIANCE.NS')\n",
    "\n",
    "stock_symbol = input('Stock symbol (e.g., RELIANCE.NS): ').strip()\n",
    "start_date = input('Start date (YYYY-MM-DD): ').strip()\n",
    "end_date = input('End date (YYYY-MM-DD): ').strip()\n",
    "\n",
    "# Provide simple defaults if user leaves blank\n",
    "if stock_symbol == '':\n",
    "    stock_symbol = 'RELIANCE.NS'\n",
    "if start_date == '':\n",
    "    start_date = '2023-01-01'\n",
    "if end_date == '':\n",
    "    end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Using: {stock_symbol} from {start_date} to {end_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Fetch historical stock data from Yahoo Finance\n",
    "try:\n",
    "    df = yf.download(stock_symbol, start=start_date, end=end_date)\n",
    "    if df.empty:\n",
    "        raise ValueError('Downloaded DataFrame is empty. Check symbol/date range or your internet connection.')\n",
    "    df.reset_index(inplace=True)\n",
    "    display(df.head())\n",
    "    print('\\nDownloaded rows:', len(df))\n",
    "except Exception as e:\n",
    "    print('Error fetching data with yfinance:', e)\n",
    "    print('\\nIf you already have a CSV, you can load it instead by setting `df = pd.read_csv(\"your_file.csv\")`')\n",
    "    df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ebf8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Basic EDA: info, describe, missing values\n",
    "if not df.empty:\n",
    "    display(df.info())\n",
    "    display(df.describe())\n",
    "    print('\\nMissing values per column:')\n",
    "    display(df.isnull().sum())\n",
    "else:\n",
    "    print('No dataframe available for EDA.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c611d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Plot Close price and moving averages\n",
    "if not df.empty:\n",
    "    df['MA7'] = df['Close'].rolling(window=7).mean()\n",
    "    df['MA21'] = df['Close'].rolling(window=21).mean()\n",
    "    df['Daily_Return'] = df['Close'].pct_change()\n",
    "\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.plot(df['Date'], df['Close'], label='Close')\n",
    "    plt.plot(df['Date'], df['MA7'], label='MA 7')\n",
    "    plt.plot(df['Date'], df['MA21'], label='MA 21')\n",
    "    plt.title(f'{stock_symbol} Close Price and Moving Averages')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No dataframe available to plot.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Feature engineering: create features and the target (next day's Close)\n",
    "if not df.empty:\n",
    "    # Create moving averages and returns (again, to be safe)\n",
    "    df['MA7'] = df['Close'].rolling(window=7).mean()\n",
    "    df['MA21'] = df['Close'].rolling(window=21).mean()\n",
    "    df['Daily_Return'] = df['Close'].pct_change()\n",
    "\n",
    "    # Shift Close to create target (predict next day's Close)\n",
    "    df['Target'] = df['Close'].shift(-1)\n",
    "\n",
    "    # Drop rows with NaN produced by rolling/shift\n",
    "    df_features = df.dropna().copy()\n",
    "\n",
    "    # Choose features used for prediction\n",
    "    feature_cols = ['Open', 'High', 'Low', 'Volume', 'MA7', 'MA21', 'Daily_Return']\n",
    "    X = df_features[feature_cols]\n",
    "    y = df_features['Target']\n",
    "\n",
    "    print('Feature matrix shape:', X.shape)\n",
    "    print('Target vector shape:', y.shape)\n",
    "else:\n",
    "    print('No dataframe available for feature engineering.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Train-test split and scaling\n",
    "if not df.empty:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    print('X_train_scaled shape:', X_train_scaled.shape)\n",
    "else:\n",
    "    print('No data to train on.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d49028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Train the model (Random Forest Regressor)\n",
    "if not df.empty:\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print('Model training completed.')\n",
    "else:\n",
    "    print('No data to train model.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Evaluate model on test set\n",
    "if not df.empty:\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f'MSE: {mse:.4f}')\n",
    "    print(f'RMSE: {rmse:.4f}')\n",
    "    print(f'R2 Score: {r2:.4f}')\n",
    "\n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(df_features['Date'].iloc[-len(y_test):], y_test.values, label='Actual (Next Close)')\n",
    "    plt.plot(df_features['Date'].iloc[-len(y_test):], y_pred, label='Predicted (Next Close)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.title('Actual vs Predicted Close Price (Test Set)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No predictions to evaluate.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d13590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Save trained model and scaler to .pkl files\n",
    "if not df.empty:\n",
    "    model_filename = f\"{stock_symbol.replace('.','_')}_stock_model.pkl\"\n",
    "    scaler_filename = f\"{stock_symbol.replace('.','_')}_stock_scaler.pkl\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    print('Saved model to', model_filename)\n",
    "    print('Saved scaler to', scaler_filename)\n",
    "else:\n",
    "    print('No model to save.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Load saved model and scaler, then make a sample prediction\n",
    "if not df.empty:\n",
    "    loaded_model = joblib.load(model_filename)\n",
    "    loaded_scaler = joblib.load(scaler_filename)\n",
    "\n",
    "    # Use the last available row's features to predict the next day's Close\n",
    "    last_features = X.iloc[[-1]]  # last row in feature matrix\n",
    "    last_scaled = loaded_scaler.transform(last_features)\n",
    "    next_close_pred = loaded_model.predict(last_scaled)[0]\n",
    "\n",
    "    print('Last available date in dataset:', df_features['Date'].iloc[-1])\n",
    "    print('Last actual Close:', df_features['Close'].iloc[-1])\n",
    "    print('Predicted next day Close (based on last row):', round(next_close_pred, 4))\n",
    "else:\n",
    "    print('No saved model to load.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293edbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) (Optional) Save the processed dataset and provide download instructions\n",
    "if not df.empty:\n",
    "    processed_csv = f\"{stock_symbol.replace('.','_')}_processed.csv\"\n",
    "    df_features.to_csv(processed_csv, index=False)\n",
    "    print('Processed dataset saved to', processed_csv)\n",
    "\n",
    "    # If running in Google Colab, trigger download\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        files.download(model_filename)\n",
    "        files.download(scaler_filename)\n",
    "        files.download(processed_csv)\n",
    "    except Exception:\n",
    "        print('\\nIf you are running this locally, find the files in your working directory.')\n",
    "else:\n",
    "    print('No processed dataset to save.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bcf339",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next steps & customization ideas\n",
    "\n",
    "- Try different models (e.g., `GradientBoostingRegressor`, `XGBoost`, `LinearRegression`) and compare results.\n",
    "- Add more features (technical indicators like RSI, MACD, Bollinger Bands).\n",
    "- Use a time-series specific approach (e.g., ARIMA, Prophet, LSTM) for potentially better sequential predictions.\n",
    "- Tune hyperparameters with `GridSearchCV` or `RandomizedSearchCV`.\n",
    "\n",
    "**This notebook follows the diabetes_prediction.ipynb step-by-step pattern:** imports, input, data load, EDA, preprocessing, train/test split, scaling, training, evaluation, saving/loading `.pkl`, and sample prediction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
