{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbfb679",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports and configuration\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import joblib\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Load the dataset (replace the filename if different)\n",
    "# Expecting a CSV with OHLCV columns for Reliance stock, e.g., Date, Open, High, Low, Close, Adj Close, Volume\n",
    "# If you already have a prepared dataset, update the path below\n",
    "csv_path = \"reliance.csv\"  # change this if your file has a different name\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    print(\"File not found:\", csv_path)\n",
    "    print(\"Please upload reliance.csv or update csv_path to your file name.\")\n",
    "else:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"Dataset loaded:\", csv_path)\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "    print(df.head())\n",
    "'''\n",
    "# Taking user input\n",
    "stock_name = input(\"Enter stock symbol (e.g., RELIANCE.NS): \")\n",
    "start_date = input(\"Enter start date (YYYY-MM-DD): \")\n",
    "end_date = input(\"Enter end date (YYYY-MM-DD): \")\n",
    "\n",
    "# Downloading dataset\n",
    "data = yf.download(stock_name, start=start_date, end=end_date)\n",
    "stock_df = pd.DataFrame(data)\n",
    "\n",
    "# Display first few rows\n",
    "print(stock_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd8ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic cleanup and feature engineering for classification (next-day Up/Down)\n",
    "# - Parse Date\n",
    "# - Sort by Date\n",
    "# - Create returns, moving averages, RSI-like features (simple), and a target: next-day up (1) vs down/flat (0)\n",
    "\n",
    "if 'df' in globals():\n",
    "    if 'Date' in df.columns:\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df = df.sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # Ensure numeric columns\n",
    "    for c in df.columns:\n",
    "        if c != 'Date':\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    # Create simple features if standard OHLCV columns exist\n",
    "    has_close = 'Close' in df.columns\n",
    "    has_open = 'Open' in df.columns\n",
    "    has_high = 'High' in df.columns\n",
    "    has_low = 'Low' in df.columns\n",
    "    has_volume = 'Volume' in df.columns\n",
    "\n",
    "    if has_close:\n",
    "        df['Return_1d'] = df['Close'].pct_change()\n",
    "        df['MA_5'] = df['Close'].rolling(5).mean()\n",
    "        df['MA_10'] = df['Close'].rolling(10).mean()\n",
    "        df['MA_20'] = df['Close'].rolling(20).mean()\n",
    "        df['STD_10'] = df['Close'].rolling(10).std()\n",
    "        df['Momentum_3'] = df['Close'] / df['Close'].shift(3) - 1\n",
    "        df['High_Low_Spread'] = np.where(has_high and has_low, (df['High'] - df['Low']) / df['Close'], np.nan)\n",
    "        df['Open_Close_Change'] = np.where(has_open, (df['Close'] - df['Open']) / df['Open'], np.nan)\n",
    "        df['Volume_Change'] = np.where(has_volume, df['Volume'].pct_change(), np.nan)\n",
    "        \n",
    "        # Target: next-day up (1) if next day's close > today's close, else 0\n",
    "        df['Close_next'] = df['Close'].shift(-1)\n",
    "        df['Target'] = (df['Close_next'] > df['Close']).astype(int)\n",
    "    \n",
    "    # Drop rows with NaNs introduced by rolling/shift\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    print(\"After feature engineering, shape:\", df.shape)\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"Dataframe df not found. Please load dataset first.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49a7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Explore dataset: info and basic plots\n",
    "if 'df' in globals():\n",
    "    print(\"Dataset Info:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # Count plot for Target\n",
    "    if 'Target' in df.columns:\n",
    "        plt.figure(figsize=(5,4))\n",
    "        sns.countplot(x='Target', data=df, palette='coolwarm')\n",
    "        plt.title('Count of Next-day Up (1) vs Not Up (0)')\n",
    "        plt.show()\n",
    "\n",
    "    # Line graph for Close and Volume if present\n",
    "    if 'Close' in df.columns:\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.plot(df['Close'].values, label='Close', color='blue')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Close')\n",
    "        plt.title('Close Price Over Time')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    if 'Volume' in df.columns:\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.plot(df['Volume'].values, label='Volume', color='orange')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Volume')\n",
    "        plt.title('Volume Over Time')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # Correlation heatmap for features\n",
    "    feature_cols = [c for c in df.columns if c not in ['Date','Target']]\n",
    "    corr = df[feature_cols].corr()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(corr, annot=False, cmap='coolwarm')\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Dataframe df not found. Please load dataset first.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train-test split\n",
    "if 'df' in globals() and 'Target' in df.columns:\n",
    "    X = df.drop(columns=['Target'])\n",
    "    if 'Date' in X.columns:\n",
    "        X = X.drop(columns=['Date'])\n",
    "    y = df['Target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=32, stratify=y\n",
    "    )\n",
    "\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train value counts:\")\n",
    "    print(y_train.value_counts())\n",
    "else:\n",
    "    print(\"Target not prepared or df missing. Please ensure previous steps succeeded.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature scaling\n",
    "if 'X_train' in globals():\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(\"Scaling complete. Shapes:\")\n",
    "    print(\"X_train_scaled:\", X_train_scaled.shape)\n",
    "    print(\"X_test_scaled:\", X_test_scaled.shape)\n",
    "else:\n",
    "    print(\"Training data not found. Run train-test split cell first.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9191656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "if 'X_train_scaled' in globals():\n",
    "    model = LogisticRegression(max_iter=1000, n_jobs=None, class_weight='balanced')\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print(\"Model trained: LogisticRegression with class_weight balanced and max_iter 1000\")\n",
    "else:\n",
    "    print(\"Scaled features not found. Please run scaling step.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90175115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions\n",
    "if 'model' in globals():\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    print(\"Predictions completed.\")\n",
    "else:\n",
    "    print(\"Model not trained yet.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate model performance\n",
    "if 'y_pred' in globals():\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No predictions found. Run the prediction cell first.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict for a new sample (use last available row's features as template)\n",
    "if 'X_test' in globals():\n",
    "    sample_features = X_test.iloc[[0]]\n",
    "    sample_scaled = scaler.transform(sample_features)\n",
    "    sample_pred = model.predict(sample_scaled)[0]\n",
    "    sample_prob = model.predict_proba(sample_scaled)[0,1]\n",
    "    print(\"Sample prediction (0=Not Up, 1=Up):\", int(sample_pred))\n",
    "    print(\"Sample probability of Up:\", float(sample_prob))\n",
    "    print(sample_features.head())\n",
    "else:\n",
    "    print(\"X_test not found. Please run previous steps.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7941f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained model and scaler\n",
    "if 'model' in globals():\n",
    "    timestamp_str = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_path = \"reliance_model_\" + timestamp_str + \".pkl\"\n",
    "    scaler_path = \"reliance_scaler_\" + timestamp_str + \".pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(\"Model saved to:\", model_path)\n",
    "    print(\"Scaler saved to:\", scaler_path)\n",
    "else:\n",
    "    print(\"Model not found. Train the model before saving.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load model and scaler (sanity check)\n",
    "if 'model_path' in globals() and 'scaler_path' in globals():\n",
    "    loaded_model = joblib.load(model_path)\n",
    "    loaded_scaler = joblib.load(scaler_path)\n",
    "    check_pred = loaded_model.predict(loaded_scaler.transform(sample_features))[0]\n",
    "    print(\"Loaded model prediction on sample:\", int(check_pred))\n",
    "    print(\"Reload sanity check completed.\")\n",
    "else:\n",
    "    print(\"Saved model paths not found. Run save cell first.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
