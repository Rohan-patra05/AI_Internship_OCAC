{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca81b29",
   "metadata": {},
   "source": [
    "# Diabetes dataset analysis and modeling\n",
    "\n",
    "This notebook follows the requested steps for the `load_diabetes` dataset:\n",
    "\n",
    "1. Data collection\n",
    "2. Data validation\n",
    "3. Data preprocessing (cleaning)\n",
    "4. Data splitting (train/test)\n",
    "5. Model selection\n",
    "6. Model training\n",
    "7. Model testing / evaluation\n",
    "8. Model prediction\n",
    "9. Model deployment (save & download)\n",
    "10. Model monitoring & maintenance\n",
    "\n",
    "**Bonus:** Automation & Pipeline Tools suggestions\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b18e7",
   "metadata": {},
   "source": [
    "## 1) Data collection\n",
    "Load the dataset via `sklearn.datasets.load_diabetes` and convert to a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b6a2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (442, 10)\n",
      "y shape: (442,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.002592  0.019907 -0.017646  \n",
       "1 -0.039493 -0.068332 -0.092204  \n",
       "2 -0.002592  0.002861 -0.025930  \n",
       "3  0.034309  0.022688 -0.009362  \n",
       "4 -0.002592 -0.031988 -0.046641  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import pandas as pd\n",
    "diabetes = load_diabetes(as_frame=True)\n",
    "X = diabetes.data.copy()\n",
    "y = diabetes.target.copy()\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db58a0d",
   "metadata": {},
   "source": [
    "## 2) Data validation\n",
    "Check for missing values, duplicate rows, dtypes, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb0dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns and dtypes:\n",
      "age    float64\n",
      "sex    float64\n",
      "bmi    float64\n",
      "bp     float64\n",
      "s1     float64\n",
      "s2     float64\n",
      "s3     float64\n",
      "s4     float64\n",
      "s5     float64\n",
      "s6     float64\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      "age    0\n",
      "sex    0\n",
      "bmi    0\n",
      "bp     0\n",
      "s1     0\n",
      "s2     0\n",
      "s3     0\n",
      "s4     0\n",
      "s5     0\n",
      "s6     0\n",
      "dtype: int64\n",
      "\n",
      "Any duplicate rows in X?  False\n",
      "\n",
      "Target (y) stats:\n",
      "count    442.000000\n",
      "mean     152.133484\n",
      "std       77.093005\n",
      "min       25.000000\n",
      "25%       87.000000\n",
      "50%      140.500000\n",
      "75%      211.500000\n",
      "max      346.000000\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target    1.000000\n",
       "bmi       0.586450\n",
       "s5        0.565883\n",
       "bp        0.441482\n",
       "s4        0.430453\n",
       "s6        0.382483\n",
       "s1        0.212022\n",
       "age       0.187889\n",
       "s2        0.174054\n",
       "sex       0.043062\n",
       "s3       -0.394789\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic validation\n",
    "print('Columns and dtypes:')\n",
    "print(X.dtypes)\n",
    "print('\\nMissing values per column:')\n",
    "print(X.isna().sum())\n",
    "print('\\nAny duplicate rows in X? ', X.duplicated().any())\n",
    "print('\\nTarget (y) stats:')\n",
    "print(y.describe())\n",
    "# Quick correlation check (features vs target)\n",
    "corr_with_target = X.join(y.rename('target')).corr()['target'].sort_values(ascending=False)\n",
    "corr_with_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d17e8",
   "metadata": {},
   "source": [
    "## 3) Data preprocessing (data cleaning)\n",
    "- No missing values in the dataset, but we'll create a reproducible preprocessing pipeline with `StandardScaler`.\n",
    "- We'll also show simple outlier detection (IQR method) and option to remove outliers (commented out by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "837d22c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected outlier rows (IQR method): 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.32713604e-01,  1.22474487e+00,  1.35772039e+00,\n",
       "         1.11474080e+00, -1.14995688e+00, -1.00587806e+00,\n",
       "        -8.54282143e-01,  3.71647064e-17,  8.90712800e-01,\n",
       "         6.98771243e-01],\n",
       "       [-1.64887544e-01, -8.16496581e-01, -1.18800534e+00,\n",
       "        -8.86076023e-01,  3.30185639e-01, -3.83428765e-01,\n",
       "         1.82581870e+00, -1.58113883e+00, -1.65448141e+00,\n",
       "        -1.81680523e+00],\n",
       "       [ 1.35715132e+00,  1.22474487e+00,  9.69800278e-01,\n",
       "        -2.85830975e-02, -1.20688544e+00, -9.80980087e-01,\n",
       "        -6.03022689e-01,  3.71647064e-17,  3.99027555e-01,\n",
       "         4.19262746e-01],\n",
       "       [-1.68692641e+00, -8.16496581e-01, -2.90940083e-01,\n",
       "        -1.31482249e+00,  1.18411402e+00,  1.37187824e+00,\n",
       "        -6.86775840e-01,  1.58113883e+00,  9.70907452e-01,\n",
       "         9.78279740e-01],\n",
       "       [-3.80509717e-02, -8.16496581e-01, -8.48575243e-01,\n",
       "         1.11474080e+00,  8.42542666e-01,  9.98408667e-01,\n",
       "         3.18261975e-01,  3.71647064e-17, -6.06166398e-01,\n",
       "        -2.79508497e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Example of simple outlier detection using IQR (not applied by default)\n",
    "def detect_outliers_iqr(df, factor=1.5):\n",
    "    outlier_index = set()\n",
    "    for col in df.columns:\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - factor * iqr\n",
    "        upper = q3 + factor * iqr\n",
    "        outlier_index.update(df[(df[col] < lower) | (df[col] > upper)].index.tolist())\n",
    "    return sorted(list(outlier_index))\n",
    "\n",
    "outliers = detect_outliers_iqr(X)\n",
    "print('Number of detected outlier rows (IQR method):', len(outliers))\n",
    "\n",
    "# Preprocessing pipeline: Standard scaling for all features (diabetes data is numeric)\n",
    "numeric_features = X.columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features)])\n",
    "\n",
    "# Show how to fit-transform a small sample (not changing original X)\n",
    "X_scaled_sample = preprocessor.fit_transform(X.iloc[:5])\n",
    "X_scaled_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8085eccf",
   "metadata": {},
   "source": [
    "## 4) Data splitting (train / test)\n",
    "We'll use `train_test_split` with a fixed random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d45e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (353, 10) Test shape: (89, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e44bbc",
   "metadata": {},
   "source": [
    "## 5) Model selection (choosing candidate algorithms)\n",
    "We'll compare:\n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n",
    "- Random Forest Regressor\n",
    "- Gradient Boosting Regressor\n",
    "\n",
    "We'll use `GridSearchCV` (with a modest parameter grid) to find a strong candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389f7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Candidate pipelines (with preprocessing)\n",
    "models = {\n",
    "    'LinearRegression': Pipeline([('pre', preprocessor), ('model', LinearRegression())]),\n",
    "    'Ridge': Pipeline([('pre', preprocessor), ('model', Ridge())]),\n",
    "    'Lasso': Pipeline([('pre', preprocessor), ('model', Lasso(max_iter=10000))]),\n",
    "    'RandomForest': Pipeline([('pre', preprocessor), ('model', RandomForestRegressor(random_state=42))]),\n",
    "    'GradientBoosting': Pipeline([('pre', preprocessor), ('model', GradientBoostingRegressor(random_state=42))])\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'LinearRegression': {},\n",
    "    'Ridge': {'model__alpha': [0.1, 1.0, 10.0]},\n",
    "    'Lasso': {'model__alpha': [0.001, 0.01, 0.1, 1.0]},\n",
    "    'RandomForest': {'model__model__n_estimators': [50, 100], 'model__model__max_depth': [None, 3, 5]},\n",
    "    'GradientBoosting': {'model__model__n_estimators': [50, 100], 'model__model__learning_rate': [0.01, 0.1], 'model__model__max_depth': [3, 5]}\n",
    "}\n",
    "\n",
    "# Note: For RandomForest and GradientBoosting, we placed the estimator under 'model' step;\n",
    "# depending on sklearn version, param names reflect the pipeline step name 'model'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2013bc1",
   "metadata": {},
   "source": [
    "## 6) Model training (Grid search for best hyperparameters)\n",
    "We'll run GridSearchCV on each candidate and pick the best model by cross-validated R² (default scoring)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17038098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training / tuning: LinearRegression\n",
      "Best CV r2: 0.4878823490667685\n",
      "Best params: {}\n",
      "\n",
      "Training / tuning: Ridge\n",
      "Best CV r2: 0.48793455930940804\n",
      "Best params: {'model__alpha': 0.1}\n",
      "\n",
      "Training / tuning: Lasso\n",
      "Best CV r2: 0.4878781553976899\n",
      "Best params: {'model__alpha': 0.001}\n",
      "\n",
      "Training / tuning: RandomForest\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'model' for estimator RandomForestRegressor(random_state=42). Valid parameters are: ['bootstrap', 'ccp_alpha', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'monotonic_cst', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ~~~~^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 854, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 320, in set_params\n    self._set_params(\"steps\", **kwargs)\n    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 69, in _set_params\n    super().set_params(**params)\n    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 295, in set_params\n    valid_params[key].set_params(**sub_params)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 283, in set_params\n    raise ValueError(\n    ...<2 lines>...\n    )\nValueError: Invalid parameter 'model' for estimator RandomForestRegressor(random_state=42). Valid parameters are: ['bootstrap', 'ccp_alpha', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'monotonic_cst', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Use 3-fold CV to keep runtime modest; adjust cv for better tuning on real runs.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m gs\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     10\u001b[0m best_estimators[name] \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     11\u001b[0m best_scores[name] \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    972\u001b[0m         clone(base_estimator),\n\u001b[0;32m    973\u001b[0m         X,\n\u001b[0;32m    974\u001b[0m         y,\n\u001b[0;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    981\u001b[0m     )\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    985\u001b[0m     )\n\u001b[0;32m    986\u001b[0m )\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_error_fast()\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     error_job\u001b[38;5;241m.\u001b[39mget_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_or_raise()\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'model' for estimator RandomForestRegressor(random_state=42). Valid parameters are: ['bootstrap', 'ccp_alpha', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'monotonic_cst', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start']."
     ]
    }
   ],
   "source": [
    "best_estimators = {}\n",
    "best_scores = {}\n",
    "\n",
    "for name, pipeline in models.items():\n",
    "    print('\\nTraining / tuning:', name)\n",
    "    param_grid = param_grids.get(name, {})\n",
    "    # Use 3-fold CV to keep runtime modest; adjust cv for better tuning on real runs.\n",
    "    gs = GridSearchCV(pipeline, param_grid=param_grid, cv=3, scoring='r2', n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_estimators[name] = gs.best_estimator_\n",
    "    best_scores[name] = gs.best_score_\n",
    "    print('Best CV r2:', gs.best_score_)\n",
    "    print('Best params:', gs.best_params_)\n",
    "    \n",
    "# Summary of CV results\n",
    "sorted_best = sorted(best_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "print('\\nModel ranking by CV R2:')\n",
    "for name, score in sorted_best:\n",
    "    print(f'{name}: {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0967e39d",
   "metadata": {},
   "source": [
    "## 7) Model testing / evaluation\n",
    "Evaluate the top models on the test set using RMSE, MAE, and R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9b6821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>53.842869</td>\n",
       "      <td>2899.054556</td>\n",
       "      <td>42.796235</td>\n",
       "      <td>0.452818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>53.851726</td>\n",
       "      <td>2900.008373</td>\n",
       "      <td>42.794066</td>\n",
       "      <td>0.452638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>53.853446</td>\n",
       "      <td>2900.193628</td>\n",
       "      <td>42.794095</td>\n",
       "      <td>0.452603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       rmse          mse        mae        r2\n",
       "Ridge             53.842869  2899.054556  42.796235  0.452818\n",
       "Lasso             53.851726  2900.008373  42.794066  0.452638\n",
       "LinearRegression  53.853446  2900.193628  42.794095  0.452603"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    preds = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    return {'rmse': rmse, 'mse': mse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "results = {}\n",
    "for name, estimator in best_estimators.items():\n",
    "    results[name] = evaluate_model(estimator, X_test, y_test)\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results).T.sort_values('r2', ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a554489d",
   "metadata": {},
   "source": [
    "## 8) Model prediction\n",
    "Use the best model to predict on new samples (here: the test set first 5 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dcadeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model on test set: Ridge\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>219.0</td>\n",
       "      <td>139.585031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>70.0</td>\n",
       "      <td>179.575695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>202.0</td>\n",
       "      <td>134.249708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>230.0</td>\n",
       "      <td>291.511770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>111.0</td>\n",
       "      <td>123.710442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true      y_pred\n",
       "287   219.0  139.585031\n",
       "211    70.0  179.575695\n",
       "72    202.0  134.249708\n",
       "321   230.0  291.511770\n",
       "73    111.0  123.710442"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose best model by test R2\n",
    "best_model_name = results_df.index[0]\n",
    "best_model = best_estimators[best_model_name]\n",
    "print('Best model on test set:', best_model_name)\n",
    "\n",
    "# Example predictions\n",
    "sample_X = X_test.iloc[:5]\n",
    "sample_y = y_test.iloc[:5]\n",
    "preds = best_model.predict(sample_X)\n",
    "pd.DataFrame({'y_true': sample_y, 'y_pred': preds})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18857523",
   "metadata": {},
   "source": [
    "## 9) Model deployment (model download)\n",
    "Save the best model as a joblib file which can be downloaded and loaded later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a8bbdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: C:/Users/ASUS/AI_Internship_OCAC_2/08_08_25/diabetes_best_model.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib, os\n",
    "model_path = 'C:/Users/ASUS/AI_Internship_OCAC_2/08_08_25/diabetes_best_model.joblib'\n",
    "joblib.dump(best_model, model_path)\n",
    "print('Saved best model to:', model_path)\n",
    "# Check file exists\n",
    "os.path.exists(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae9de1",
   "metadata": {},
   "source": [
    "## 10) Model monitoring and maintenance\n",
    "Recommendations:\n",
    "- Track performance metrics (RMSE, MAE, R²) over time.\n",
    "- Monitor data drift (feature distribution changes) and label drift.\n",
    "- Retrain on new data periodically or when performance degrades.\n",
    "- Use validation & production holds for safe deployment.\n",
    "\n",
    "**Suggested tools:** MLflow (experiment tracking), Prometheus/Grafana (metrics), Seldon/TFServing or FastAPI (model serving), Great Expectations (data validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2871f1fa",
   "metadata": {},
   "source": [
    "### Bonus: Automation & Pipeline Tools\n",
    "- Convert the preprocessing+model into a sklearn `Pipeline` (already used here).\n",
    "- CI/CD: use GitHub Actions to run tests, training and push model artifacts to a model registry.\n",
    "- Orchestrate with Airflow or Prefect to schedule retraining and monitoring jobs.\n",
    "- For production features: use feature stores (Feast) and model registries.\n",
    "\n",
    "---\n",
    "\n",
    "End of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4de5f6c-7546-44d2-b147-bbd752f2ef6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
